{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the modules\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training model\n",
    "\n",
    "detector=tf.keras.models.load_model(\"emotion_detector.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining class names\n",
    "\n",
    "class_names=['angry', 'happy', 'relaxed', 'sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load and preprocess image\n",
    "\n",
    "def image_processing(image_paths):\n",
    "    images=[]\n",
    "    for path in image_paths:\n",
    "        image=cv2.imread(path)\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image=cv2.resize(image,(192,192))\n",
    "        images.append(image)\n",
    "    images=np.asarray(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image path\n",
    "image1=\"images_for_test\\\\angry.webp\"\n",
    "image2=\"images_for_test\\\\happy.png\"\n",
    "image3=\"images_for_test\\\\sad.webp\"\n",
    "image4=\"images_for_test\\\\relaxed.jpg\"\n",
    "\n",
    "image_paths=[image1,image2,image3,image4]\n",
    "\n",
    "images=image_processing(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of images\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "i = 0\n",
    "for x in range(2):\n",
    "    for y in range(2):\n",
    "        prediction = detector.predict(images[i][None, ...], verbose=0)[0]\n",
    "        \n",
    "        axs[x][y].set_xticks([])\n",
    "        axs[x][y].set_yticks([])\n",
    "        axs[x][y].set_xlabel(f'prediction: {class_names[np.argmax(prediction)]}')\n",
    "        \n",
    "        axs[x][y].imshow(images[i])\n",
    "        \n",
    "        i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using model with webcam\n",
    "\n",
    "cam=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _,frame=cam.read()\n",
    "    frame=cv2.flip(frame,1)\n",
    "    image=cv2.resize(frame,(192,192))\n",
    "    prediction=class_names[np.argmax(detector.predict(image.reshape(1,192,192,3),verbose=0))]\n",
    "    cv2.putText(frame, prediction, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA) \n",
    "    cv2.imshow(\"image\",frame)\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
